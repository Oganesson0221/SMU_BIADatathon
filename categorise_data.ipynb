{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rishi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/rishi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorized data saved to wikileaks_categorized.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "# Ensure you have the punkt tokenizer downloaded\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Define categories and keywords\n",
    "categories = {\n",
    "    \"Allegations\": [\"allegation\", \"irregularity\", \"accused\", \"suspected\", \"claimed\"],\n",
    "    \"Criminal Violations\": [\"criminal\", \"violation\", \"illegal\", \"fraud\", \"offense\"],\n",
    "    \"Sentencing\": [\"sentenced\", \"punishment\", \"penalty\", \"fined\", \"jailed\"],\n",
    "    \"Background Information\": [\"background\", \"context\", \"history\", \"information\"],\n",
    "}\n",
    "\n",
    "# Define function to categorize sentences\n",
    "def categorize_sentence(sentence):\n",
    "    for category, keywords in categories.items():\n",
    "        if any(keyword.lower() in sentence.lower() for keyword in keywords):\n",
    "            return category\n",
    "    return \"Other\"\n",
    "\n",
    "# Load Excel data\n",
    "file_path = \"wikileaks_parsed.xlsx\"  # Adjust if the file has a different name or location\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ensure 'Text' column exists\n",
    "if \"Text\" not in df.columns:\n",
    "    raise ValueError(\"The Excel file must have a 'Text' column.\")\n",
    "\n",
    "# Split text into sentences and categorize\n",
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    pdf_path = row[\"PDF Path\"]\n",
    "    text = row[\"Text\"]\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        category = categorize_sentence(sentence)\n",
    "        data.append({\n",
    "            \"PDF Path\": pdf_path,\n",
    "            \"Sentence\": sentence,\n",
    "            \"Category\": category,\n",
    "        })\n",
    "\n",
    "# Create a new DataFrame with categorized sentences\n",
    "categorized_df = pd.DataFrame(data)\n",
    "\n",
    "# Save to a new Excel file\n",
    "output_file = \"wikileaks_categorized.xlsx\"\n",
    "categorized_df.to_excel(output_file, index=False)\n",
    "print(f\"Categorized data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorized data saved to wikileaks_categorized.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rishi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "# Ensure you have the punkt tokenizer downloaded\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Define categories and keywords\n",
    "categories = {\n",
    "    \"Allegations\": [\"allegation\", \"irregularity\", \"accused\", \"suspected\", \"claimed\"],\n",
    "    \"Criminal Violations\": [\"criminal\", \"violation\", \"illegal\", \"fraud\", \"offense\"],\n",
    "    \"Sentencing\": [\"sentenced\", \"punishment\", \"penalty\", \"fined\", \"jailed\"],\n",
    "    \"Background Information\": [\"background\", \"context\", \"history\", \"information\"],\n",
    "}\n",
    "\n",
    "# Define function to categorize sentences\n",
    "def categorize_sentence(sentence):\n",
    "    scores = defaultdict(int)  # A dictionary to track scores for each category\n",
    "    \n",
    "    # Count the occurrences of keywords for each category\n",
    "    for category, keywords in categories.items():\n",
    "        for keyword in keywords:\n",
    "            scores[category] += sentence.lower().count(keyword.lower())\n",
    "    \n",
    "    # Assign the sentence to the category with the highest score\n",
    "    if scores:\n",
    "        return max(scores, key=scores.get)  # Category with the highest score\n",
    "    return None  # This shouldn't happen since there's always a category\n",
    "\n",
    "# Load Excel data\n",
    "file_path = \"wikileaks_parsed.xlsx\"  # Adjust if the file has a different name or location\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ensure 'Text' column exists\n",
    "if \"Text\" not in df.columns:\n",
    "    raise ValueError(\"The Excel file must have a 'Text' column.\")\n",
    "\n",
    "# Split text into sentences and categorize\n",
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    pdf_path = row[\"PDF Path\"] if \"PDF Path\" in row else None\n",
    "    text = row[\"Text\"]\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        category = categorize_sentence(sentence)\n",
    "        data.append({\n",
    "            \"PDF Path\": pdf_path,\n",
    "            \"Sentence\": sentence,\n",
    "            \"Category\": category,\n",
    "        })\n",
    "\n",
    "# Create a new DataFrame with categorized sentences\n",
    "categorized_df = pd.DataFrame(data)\n",
    "\n",
    "# Save to a new Excel file\n",
    "output_file = \"wikileaks_categorized.xlsx\"\n",
    "categorized_df.to_excel(output_file, index=False)\n",
    "print(f\"Categorized data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishi/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rishi/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rishi/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Allegations       0.94      1.00      0.97       171\n",
      "Background Information       1.00      0.14      0.25         7\n",
      "   Criminal Violations       0.00      0.00      0.00         4\n",
      "\n",
      "              accuracy                           0.95       182\n",
      "             macro avg       0.65      0.38      0.41       182\n",
      "          weighted avg       0.93      0.95      0.92       182\n",
      "\n",
      "Categorized data saved to wikileaks_ml_categorized.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load labeled data\n",
    "labeled_file = \"wikileaks_categorized.xlsx\"  # Replace with your labeled file\n",
    "labeled_df = pd.read_excel(labeled_file)\n",
    "\n",
    "# Ensure required columns\n",
    "if \"Sentence\" not in labeled_df.columns or \"Category\" not in labeled_df.columns:\n",
    "    raise ValueError(\"The labeled dataset must have 'Sentence' and 'Category' columns.\")\n",
    "\n",
    "# Step 2: Split data into training and test sets\n",
    "X = labeled_df[\"Sentence\"]\n",
    "y = labeled_df[\"Category\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 4: Train a classifier (Logistic Regression in this example)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model and vectorizer for future use\n",
    "joblib.dump(model, \"text_classifier_model.pkl\")\n",
    "joblib.dump(vectorizer, \"text_vectorizer.pkl\")\n",
    "\n",
    "# Step 6: Load your full dataset and categorize sentences\n",
    "file_path = \"wikileaks_parsed.xlsx\"  # Replace with your dataset\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "if \"Text\" not in df.columns:\n",
    "    raise ValueError(\"The Excel file must have a 'Text' column.\")\n",
    "\n",
    "# Load saved model and vectorizer\n",
    "model = joblib.load(\"text_classifier_model.pkl\")\n",
    "vectorizer = joblib.load(\"text_vectorizer.pkl\")\n",
    "\n",
    "# Process sentences\n",
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    pdf_path = row[\"PDF Path\"] if \"PDF Path\" in row else None\n",
    "    text = row[\"Text\"]\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Predict category for each sentence\n",
    "        sentence_tfidf = vectorizer.transform([sentence])\n",
    "        category = model.predict(sentence_tfidf)[0]\n",
    "        data.append({\n",
    "            \"PDF Path\": pdf_path,\n",
    "            \"Sentence\": sentence,\n",
    "            \"Category\": category,\n",
    "        })\n",
    "\n",
    "# Save results\n",
    "categorized_df = pd.DataFrame(data)\n",
    "output_file = \"wikileaks_ml_categorized.xlsx\"\n",
    "categorized_df.to_excel(output_file, index=False)\n",
    "print(f\"Categorized data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison complete. Results saved to similarity_results.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Load the processed Excel files\n",
    "wikileaks_file = \"processed_wikileaks_parsed.xlsx\"\n",
    "news_file = \"processed_news_excerpts_parsed.xlsx\"\n",
    "\n",
    "wikileaks_df = pd.read_excel(wikileaks_file)\n",
    "news_df = pd.read_excel(news_file)\n",
    "\n",
    "# Load SpaCy model for NLP\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_similarity(text1, text2):\n",
    "    \"\"\"Compute similarity between two texts using SequenceMatcher.\"\"\"\n",
    "    return SequenceMatcher(None, text1, text2).ratio()\n",
    "\n",
    "def find_similar_entries(news_text, wikileaks_df):\n",
    "    \"\"\"Find similar entries from the Wikileaks dataset for a given news text.\"\"\"\n",
    "    results = []\n",
    "    for _, row in wikileaks_df.iterrows():\n",
    "        similarity = get_similarity(news_text, row['Text'])\n",
    "        if similarity > 0.5:  # Threshold for similarity\n",
    "            results.append({\n",
    "                'PDF Path': row['PDF Path'],\n",
    "                'Wikileaks Text': row['Text'],\n",
    "                'Similarity': similarity,\n",
    "                'Entities': row['entities'],\n",
    "                'Relationships': row['relationships']\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Process news articles and compare them with Wikileaks data\n",
    "output = []\n",
    "for _, news_row in news_df.iterrows():\n",
    "    similar_entries = find_similar_entries(news_row['Text'], wikileaks_df)\n",
    "    for entry in similar_entries:\n",
    "        output.append({\n",
    "            'News Link': news_row['Link'],\n",
    "            'News Text': news_row['Text'],\n",
    "            'Category': news_row['Category'],\n",
    "            'Wikileaks PDF': entry['PDF Path'],\n",
    "            'Wikileaks Text': entry['Wikileaks Text'],\n",
    "            'Similarity': entry['Similarity'],\n",
    "            'News Entities': news_row['entities'],\n",
    "            'Wikileaks Entities': entry['Entities'],\n",
    "            'Relationships': entry['Relationships']\n",
    "        })\n",
    "\n",
    "# Save the results to a new Excel file\n",
    "output_df = pd.DataFrame(output)\n",
    "output_df.to_excel(\"similarity_results.xlsx\", index=False)\n",
    "\n",
    "print(\"Comparison complete. Results saved to similarity_results.xlsx.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity results saved to similarity_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_data(wikileaks_file, news_file):\n",
    "    # Load the processed data from Excel files\n",
    "    wikileaks_df = pd.read_excel(wikileaks_file)\n",
    "    news_df = pd.read_excel(news_file)\n",
    "    return wikileaks_df, news_df\n",
    "\n",
    "def calculate_similarity(wikileaks_df, news_df):\n",
    "    # Combine text data from Wikileaks and News\n",
    "    wikileaks_texts = wikileaks_df['Text']\n",
    "    news_texts = news_df['Text']\n",
    "\n",
    "    # Use TF-IDF to vectorize the text data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    combined_texts = pd.concat([wikileaks_texts, news_texts])\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined_texts)\n",
    "\n",
    "    # Split the TF-IDF matrix for Wikileaks and News\n",
    "    wikileaks_tfidf = tfidf_matrix[:len(wikileaks_texts)]\n",
    "    news_tfidf = tfidf_matrix[len(wikileaks_texts):]\n",
    "\n",
    "    # Calculate cosine similarity between Wikileaks and News texts\n",
    "    similarity_matrix = cosine_similarity(wikileaks_tfidf, news_tfidf)\n",
    "    return similarity_matrix\n",
    "\n",
    "def categorize_and_cite(similarity_matrix, wikileaks_df, news_df, threshold=0.5):\n",
    "    results = []\n",
    "    for i, wikileaks_row in wikileaks_df.iterrows():\n",
    "        for j, news_row in news_df.iterrows():\n",
    "            similarity_score = similarity_matrix[i, j]\n",
    "            if similarity_score >= threshold:\n",
    "                result = {\n",
    "                    'Wikileaks PDF Path': wikileaks_row['PDF Path'],\n",
    "                    'Wikileaks Text': wikileaks_row['Text'],\n",
    "                    'News Link': news_row['Link'],\n",
    "                    'News Text': news_row['Text'],\n",
    "                    'Similarity Score': similarity_score,\n",
    "                    'Entities Matched': set(wikileaks_row['entities']) & set(news_row['entities']),\n",
    "                    'Relationships Matched': set(wikileaks_row['relationships']) & set(news_row['relationships']),\n",
    "                }\n",
    "                results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def save_results(results_df, output_file):\n",
    "    # Save the results to an Excel file\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths for input and output\n",
    "    wikileaks_file = \"wikileaks_parsed.xlsx\"\n",
    "    news_file = \"news_excerpts_parsed.xlsx\"\n",
    "    output_file = \"similarity_results.xlsx\"\n",
    "\n",
    "    # Load data\n",
    "    wikileaks_df, news_df = load_data(wikileaks_file, news_file)\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarity_matrix = calculate_similarity(wikileaks_df, news_df)\n",
    "\n",
    "    # Categorize and cite similarities\n",
    "    results_df = categorize_and_cite(similarity_matrix, wikileaks_df, news_df)\n",
    "\n",
    "    # Save results\n",
    "    save_results(results_df, output_file)\n",
    "\n",
    "    print(f\"Similarity results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              news_link wikileaks_pdf_path  \\\n",
      "0     https://edition.cnn.com/2023/09/29/business/st...             89.pdf   \n",
      "1     https://www.channelnewsasia.com/singapore/su-w...             89.pdf   \n",
      "2     https://edition.cnn.com/2023/05/22/tech/meta-f...             89.pdf   \n",
      "3     https://www.channelnewsasia.com/singapore/bill...             89.pdf   \n",
      "4     https://edition.cnn.com/2024/03/05/politics/li...             89.pdf   \n",
      "...                                                 ...                ...   \n",
      "1504  https://www.channelnewsasia.com/commentary/mal...             89.pdf   \n",
      "1505  https://www.channelnewsasia.com/singapore/tick...             89.pdf   \n",
      "1506     https://www.bbc.com/news/world-europe-57965260             89.pdf   \n",
      "1507  https://www.bbc.com/news/uk-wales-mid-wales-13...             89.pdf   \n",
      "1508  https://www.straitstimes.com/singapore/parliam...             89.pdf   \n",
      "\n",
      "      similarity_score    category  \\\n",
      "0             0.317713  Allegation   \n",
      "1             0.311477  Allegation   \n",
      "2             0.329051  Allegation   \n",
      "3             0.307117  Allegation   \n",
      "4             0.320333  Allegation   \n",
      "...                ...         ...   \n",
      "1504          0.319737  Allegation   \n",
      "1505          0.317234  Allegation   \n",
      "1506          0.310744  Allegation   \n",
      "1507          0.311342  Allegation   \n",
      "1508          0.325220  Allegation   \n",
      "\n",
      "                               sentencing_or_conclusion  \n",
      "0     [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "1     [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "2     [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "3     [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "4     [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "...                                                 ...  \n",
      "1504  [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "1505  [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "1506  [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "1507  [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "1508  [('the European Aeronautic', 'ORG'), ('Space C...  \n",
      "\n",
      "[1509 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the data from Excel files\n",
    "wikileaks_df = pd.read_excel(\"wikileaks_parsed.xlsx\")\n",
    "news_df = pd.read_excel(\"news_excerpts_parsed.xlsx\")\n",
    "processed_wikileaks_df = pd.read_excel(\"processed_wikileaks_parsed.xlsx\")\n",
    "processed_news_df = pd.read_excel(\"processed_news_excerpts_parsed.xlsx\")\n",
    "\n",
    "# Load spaCy model for named entity recognition (NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Preprocess text (tokenize, remove stopwords, and lemmatize)\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "wikileaks_df['clean_text'] = wikileaks_df['Text'].apply(preprocess_text)\n",
    "news_df['clean_text'] = news_df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Use TfidfVectorizer to convert the text into vectors for similarity computation\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def compute_similarity(query, text_list):\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_list + [query])  # Append query to text list\n",
    "    return cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n",
    "\n",
    "# Example of how to categorize and extract similarity with a sample news excerpt\n",
    "def get_similar_wikileaks_content(news_row):\n",
    "    news_text = news_row['clean_text']\n",
    "    similarities = compute_similarity(news_text, wikileaks_df['clean_text'])\n",
    "    best_match_index = similarities.argmax()\n",
    "    \n",
    "    # Fetch best matching wikileaks case\n",
    "    best_match_row = wikileaks_df.iloc[best_match_index]\n",
    "    category = \"Allegation\"  # Default to 'Allegation' or use a rule to determine categories\n",
    "    # Check if the category already exists in the processed data and assign\n",
    "    if 'Category' in best_match_row and best_match_row['Category']:\n",
    "        category = best_match_row['Category']\n",
    "    \n",
    "    # Assuming 'sentencing' or 'conclusion' info is available in the processed_wikileaks_df\n",
    "    sentence_or_conclusion = processed_wikileaks_df[processed_wikileaks_df['PDF Path'] == best_match_row['PDF Path']]['entities'].iloc[0]\n",
    "    \n",
    "    return {\n",
    "        \"news_link\": news_row['Link'],\n",
    "        \"wikileaks_pdf_path\": best_match_row['PDF Path'],\n",
    "        \"similarity_score\": similarities[best_match_index],\n",
    "        \"category\": category,\n",
    "        \"sentencing_or_conclusion\": sentence_or_conclusion\n",
    "    }\n",
    "\n",
    "# Iterate through news_df and find similarities\n",
    "results = []\n",
    "for index, news_row in news_df.iterrows():\n",
    "    result = get_similar_wikileaks_content(news_row)\n",
    "    results.append(result)\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'wikileaks_news_similarity_results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results DataFrame to an Excel file\n",
    "results_df.to_excel(\"wikileaks_news_similarity_results.xlsx\", index=False)\n",
    "\n",
    "print(\"Results saved to 'wikileaks_news_similarity_results.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd47627d1e054c81b6f540a9d13a3b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d07fc35fb3408198a9a56a4558db0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa79da7bdb343b3a4bd4146a7fc6a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a67fbcbbee4daba90548eeff9e341e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22638c6e39b466fb14ee3f3301029ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ba3ad0fc5b45ddb22669edc83f8ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization complete and saved to 'wikileaks_parsed_with_categories.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('wikileaks_parsed.xlsx')\n",
    "\n",
    "# Load a pre-trained text classification model\n",
    "# In this case, we can use a zero-shot classification model from Hugging Face\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "\n",
    "# Define possible categories\n",
    "candidate_labels = ['Allegation', 'Investigative Details', 'Background Information', 'Charges', 'Sentencing', 'Criminal Violations']\n",
    "\n",
    "# Function to classify each row of text\n",
    "def classify_text(text):\n",
    "    result = classifier(text, candidate_labels)\n",
    "    return result['labels'][0]  # Return the top predicted label\n",
    "\n",
    "# Apply the function to the 'Text' column\n",
    "data['Category'] = data['Text'].apply(classify_text)\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "data.to_excel('wikileaks_parsed_with_categories.xlsx', index=False)\n",
    "\n",
    "print(\"Categorization complete and saved to 'wikileaks_parsed_with_categories.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress at row 100\n",
      "Saved progress at row 200\n",
      "Saved progress at row 300\n",
      "Saved progress at row 400\n",
      "Saved progress at row 500\n",
      "Saved progress at row 600\n",
      "Saved progress at row 700\n",
      "Saved progress at row 800\n",
      "Saved progress at row 900\n",
      "Saved progress at row 1000\n",
      "Saved progress at row 1100\n",
      "Saved progress at row 1200\n",
      "Saved progress at row 1300\n",
      "Saved progress at row 1400\n",
      "Saved progress at row 1500\n",
      "Categorization complete and saved to 'news_excerpts_parsed_with_categories.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# Load the data from the Excel file\n",
    "data = pd.read_excel('news_excerpts_parsed.xlsx')\n",
    "\n",
    "# Load the zero-shot classification model\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "\n",
    "# Define the candidate labels\n",
    "candidate_labels = ['Allegation', 'Investigative Details', 'Background Information', 'Charges', 'Sentencing', 'Criminal Violations']\n",
    "\n",
    "# Check if a previous output file exists\n",
    "output_file = 'news_excerpts_parsed_with_categories.xlsx'\n",
    "if os.path.exists(output_file):\n",
    "    # Load the previously processed data\n",
    "    existing_data = pd.read_excel(output_file)\n",
    "    processed_indices = existing_data.index.tolist()\n",
    "else:\n",
    "    # If no previous progress, start fresh\n",
    "    processed_indices = []\n",
    "\n",
    "# Function to classify the text based on the context\n",
    "def classify_text(text):\n",
    "    result = classifier(text, candidate_labels)\n",
    "    return result['labels'][0]  # Returning the top predicted category\n",
    "\n",
    "# Apply classification only to unprocessed rows\n",
    "def process_data(data):\n",
    "    for index, row in data.iterrows():\n",
    "        if index not in processed_indices:\n",
    "            # Classify the text and add the category\n",
    "            category = classify_text(row['Text'])\n",
    "            data.at[index, 'Category'] = category\n",
    "            \n",
    "            # Save progress periodically to avoid losing data\n",
    "            if (index + 1) % 100 == 0:  # Save progress every 100 rows\n",
    "                data.to_excel(output_file, index=False)\n",
    "                print(f\"Saved progress at row {index + 1}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process the data (classify and save progress)\n",
    "data = process_data(data)\n",
    "\n",
    "# Save the final result\n",
    "data.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Categorization complete and saved to 'news_excerpts_parsed_with_categories.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar Citation: \"Allegation\n",
      "\n",
      "In July 2004, the Investigation Task Force (ITF) was provided with a copy of a letter dated 28 May 2004, from the Cargo Manager of an Airline to a Staff Member of Public Enterprise Airport Pristina. In the letter, the Cargo Manager referred to several problems relative to an Invoice for April 2004 issued by the Cargo Department of Pristina Airport for the handling of the outgoing mail of a Member State’s KFOR. At the time, Pristina Airport staff could not locate a record of this invoice in the airport’s financial records, and, therefore, the commission of fraud on the part of staff in the Cargo Department was suspected.\"\n",
      "Categories: Allegation\n",
      "Similarity Score: 0.34018653631210327\n",
      "\n",
      "\n",
      "Most Similar Citation: Non Staff member 1’s statements provided to the ITF Investigators, disclosed the following  two distinct cases:  \n",
      "\n",
      "Case-B  \n",
      "\n",
      "Non Staff member 1 stated that he/she was aware of another case of kickbacks for Pristina Airport employment, which occurred circa 6 September 2004. Non Staff member 1, in his role as the owner of a hamburger/sandwich stand/restaurant - well-frequented by airport employees – said he/she was contacted by KPS officer 2 who requested information in relation to what business connections Non Staff member 4 had within Pristina Airport. \n",
      "\n",
      "Non Staff member 1 stated that Non Staff member 5, the wife of KPS Officer 2 met Non Staff member 4 in the clothing boutique where he/she worked, while he/she was purchasing airport uniforms. At that time, he/she had asked him/her how to obtain a job  at the airport. He/she allegedly replied he/she had no problems in getting him/her a job at  Pristina Airport due to his/her important airport contacts, but it would cost him/her € 3.000,00.\n",
      "Categories: Investigative Details\n",
      "Similarity Score: 0.33965879678726196\n",
      "\n",
      "\n",
      "Most Similar Citation: \"When asked by the ITF to substantiate his/her allegation that Procurement Officer 1 and the Finance Officer had accepted bribes from Vendor 2, Vendor 1 Manager said that he/she had heard the rumours in Pristina coffee bars but that he/she could not remember from whom he/she had heard these rumours. He/she said that the witnesses to whom he/she had referred in his letter of complaint were actually the same persons from whom he/she heard the rumours. Vendor 1 Manager was unable to suggest which representative of Vendor 2 had paid the bribes.\n",
      "\n",
      "Vendor 2 Employee who attended the meeting of the Bid Opening Committee; Vendor 2 Manager; and Vendor 2 Director all told ITF that they had not paid bribes to Procurement Officer 1 and/or the Finance Officer.\n",
      "\n",
      "Procurement Officer 1 and the Finance Officer both denied accepting bribes or any other consideration from any person in this matter.\"\n",
      "Categories: Allegation\n",
      "Similarity Score: 0.33246108889579773\n",
      "\n",
      "\n",
      "Most Similar Citation: Non Staff member 1’s statements provided to the ITF Investigators, disclosed the following  two distinct cases:  \n",
      "\n",
      "Case A \n",
      "\n",
      "On either 30 or 31 July 2004, Non Staff member 1 said he/she was contacted by Official 1’s  daughter, Official 2’s Secretary, requesting him/her to come to Restaurant 1 located in  Hajvali.  \n",
      "\n",
      "Non Staff member 1 stated that he/she was personally greeted upon his arrival by Security  Official, Official 2’s Secretary and Official 1 and another person, male, but name unknown,  who was there seeking a similar employment route.  \n",
      "\n",
      "According to Non Staff member 1, the other person paid, in his presence, the sum of  €10.000,00 to Official 2’s Secretary, just before Non Staff member 1 himself/herself handed  €5.000,00 to the same person\n",
      "\n",
      "After both persons had paid the agreed upon cash amounts, they were both requested to sign  three different coloured books entitled “Airport Staff”, and then asked to leave because they  would be contacted by telephone as to the details of their future employment at Pristina  Airport.  \n",
      "Categories: Investigative Details\n",
      "Similarity Score: 0.3236696124076843\n",
      "\n",
      "\n",
      "Most Similar Citation: Non Staff member 1’s statements provided to the ITF Investigators, disclosed the following two distinct cases: Case A Non Staff member 1 told the ITF that he/she was called again, two days later, in order to pay an additional € 1.000,00, which he/she had then given to Official 2’s Secretary, in the presence of his/her father, Official 1, during a dinner that Official 1 and his daughter were having at the same mentioned restaurant. Non Staff member 1 also said that he/she paid approximately € 180 for that night’s dinner and that he/she was called, always by Official 2’s Secretary, to two further dinners at Restaurant 2 and at Restaurant 1. Non-Staff member 1 was requested to pay, amounts of € 225 and € 190 for the dinners. Non Staff member 1 stated that during the dinner, the following Pristina Airport staff were present: Security Official, a Secretary, Official 2, X-Ray Official, Official 1, Official 2’s Secretary, Official 3, Official 4 and one person who only spoke English (name unknown). This person may have been Official 5, because Non Staff member 1 stated that this person was not a Kosovar, but an International and furthermore, at a certain point when this person was not present, all the others congratulated Non Staff member 1 for his new job. The Investigators believe that the above-mentioned Airport staff were attempting to demonstrate to Non Staff member 1 that they were in contact with the competent person who could authorize his employment.\n",
      "Categories: Investigative Details\n",
      "Similarity Score: 0.317464679479599\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "wikileaks_data = pd.read_excel('wikileaks_parsed_with_categories.xlsx')\n",
    "news_data = pd.read_excel('news_excerpts_parsed_with_categories.xlsx')\n",
    "\n",
    "# Initialize the Sentence-BERT model for text embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get the embedding for a list of texts\n",
    "def get_embeddings(texts):\n",
    "    return model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "# Get embeddings for the Wikileaks data and the news article text\n",
    "wikileaks_embeddings = get_embeddings(wikileaks_data['Text'].tolist()).cpu().numpy()\n",
    "news_data['embedding'] = news_data['Text'].apply(lambda x: model.encode(x))  # Removed `.cpu()`\n",
    "\n",
    "# Function to retrieve the most similar wikileaks excerpts based on cosine similarity\n",
    "def find_most_similar_citations(news_article_text):\n",
    "    # Get the embedding of the news article (already a NumPy array)\n",
    "    news_article_embedding = model.encode(news_article_text)  # Removed `.cpu()`\n",
    "    \n",
    "    # Compute cosine similarities between the news article and all wikileaks excerpts\n",
    "    similarities = cosine_similarity([news_article_embedding], wikileaks_embeddings)\n",
    "    \n",
    "    # Get the indices of the most similar wikileaks citations\n",
    "    most_similar_indices = np.argsort(similarities[0])[::-1]\n",
    "    \n",
    "    similar_citations = []\n",
    "    \n",
    "    # Get top N most similar citations and their categories\n",
    "    for index in most_similar_indices[:5]:  # Adjust the number 5 as needed\n",
    "        citation_text = wikileaks_data.iloc[index]['Text']\n",
    "        categories = wikileaks_data.iloc[index]['Category']\n",
    "        similarity_score = similarities[0][index]\n",
    "        \n",
    "        # Append the citation text, its categories, and similarity score\n",
    "        similar_citations.append({\n",
    "            'Citation Text': citation_text,\n",
    "            'Categories': categories,\n",
    "            'Similarity Score': similarity_score\n",
    "        })\n",
    "    \n",
    "    return similar_citations\n",
    "\n",
    "# Example usage:\n",
    "news_article = \"Starbucks violated federal labor law when it increased wages and offered new perks and benefits only to non-union employees, a National Labor Relations Board judge found Thursday. The decision is the latest in a series of NLRB rulings finding that Starbucks has violated labor law in its efforts to stop unions from forming in its coffee shops. The issue at the heart of this case is whether, under current Board law, [Starbucks] was entitled to explicitly reward employees, for not participating in union activity, while falsely telling its workers that the federal labor law forced it to take this action, wrote administrative law judge Mara-Louise Anzalone. It was not.\"\n",
    "similar_citations = find_most_similar_citations(news_article)\n",
    "\n",
    "for citation in similar_citations:\n",
    "    print(f\"Most Similar Citation: {citation['Citation Text']}\")\n",
    "    print(f\"Categories: {citation['Categories']}\")\n",
    "    print(f\"Similarity Score: {citation['Similarity Score']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar Citation: \"IV. CRIMINAL VIOLATIONS\n",
      "\n",
      "Based on the referral from the ITF to the Department of Justice on 26 July 2004, arrest warrants were issued against Official 1 and Official 2. Each charge is detailed below:\n",
      "\n",
      "Count 1\n",
      "\n",
      "That between the dates 14th March 2004 and 16th March 2004 inclusive, Official 1 and Official 2 acting in their capacity as officials of Airport Pristina, and acting in complicity with the intention to obtain an unlawful material benefit, presented a representative of the Company with a false statement of account claiming reduced storage fees, and in so doing, misled an authorized person to carry out an unlawful payment, thereby committing the offence of Fraud in Service in violation of Article 215, (1) and (2) of the Kosovo Criminal Code (KCC) punishable by imprisonment of one to ten years\n",
      "\n",
      "{equivalent to Fraud in Office contrary to Article 341 (1) and (2) of Provisional Kosovo Criminal Code (PCCK)};\n",
      "\n",
      "and Complicity, in violation of Article 22 of Criminal Code of SFRY,( equivalent to Co- Perpetration, in violation of PCCK Article 23)\"\n",
      "Categories: Criminal Violations\n",
      "Similarity Score: 0.48282527923583984\n",
      "\n",
      "\n",
      "Most Similar Citation: \"ITF investigators visited the Border Boundary Police and interviewed two current investigators. Neither officer recalled the incident, but they made extensive enquiries in an attempt to trace the police report and locate the €5,200. They were unsuccessful on both counts.\n",
      "\n",
      "On 27 September 2004, the ITF sent a letter to UNMIK Police Officer 2, in an effort to determine what investigations had been undertaken into the matter, the result of those investigations, and the whereabouts of the money.\n",
      "\n",
      "The UNMIK Police Officer 2 indicated that Regional Crime Squad Pristina Region was undertaking an investigation into the matter, which therefore remains an open investigation.\"\n",
      "Categories: Allegation\n",
      "Similarity Score: 0.4310215711593628\n",
      "\n",
      "\n",
      "Most Similar Citation: Investigative details\n",
      "\n",
      "In his/her interviews conducted on 31st August and 14th September 2004, Vendor 1 and Vendor 2 Representative admitted that the fact that both Vendor 1 and Vendor 2 took part together in three Airport tenders put other competitors at a disadvantage, but alleged both companies have never exchanged information with regard to the price offers.\n",
      "\n",
      "There were doubts whether both companies Vendor 3 and Vendor 4 exist and submitted bids for the three tenders. The ITF investigation, with support from the Kosovo Organised Crime Bureau (KOCB), has found no reference with regard to the existence of the alleged competitor Vendor 4 in Pristina. The alleged company Vendor 3 was found to be a supermarket located in Prizren.\n",
      "\n",
      "The above-mentioned facts are already part of the ITF case no. 286/04 that was submitted to the International Prosecutor, UNMIK Department of Justice, in October 2004. On 1 December 2004, the ITF contacted the International Prosecutor for a legal assessment of this case. Although this case would clearly be a breach of Economic Law, there is no applicable law in Kosovo for the time being.\n",
      "Categories: Investigative Details\n",
      "Similarity Score: 0.41600140929222107\n",
      "\n",
      "\n",
      "Most Similar Citation: \"INTRODUCTION\n",
      "\n",
      "This case arises out of an audit report dated 28 February 2003 into the financial statements of Pristina International Airport conducted by the Chartered Accountants which led to an investigation concerning alleged corruption and irregularities arising in the course of procurements and contracts at Pristina International Airport.\n",
      "It is alleged that a single source contract for one container was added one month after a main contract for the supply of two new containers and the dismantling, transport and re-construction of a further seven containers at Pristina Airport.\n",
      "\n",
      "METHODOLOGY\n",
      "\n",
      "This investigation was conducted pursuant to Executive Decision No 2003/16 on the establishment of the Investigation Task Force. The ITF investigators conducted an enquiry into the allegations raised by interviews with persons indicated to be witnesses and persons potentially implicated in the allegations; by obtaining documents from the Pristina Airport administration and from Pillar IV, which were then analysed for relevance to the inquiry at hand.\"\n",
      "Categories: Background Information\n",
      "Similarity Score: 0.3818971812725067\n",
      "\n",
      "\n",
      "Most Similar Citation: \"III. INVESTIGATIVE DETAILS\n",
      "\n",
      "The charges themselves, as calculated by the Airport Handling Services Department for Airline flights, were scrutinized against the published \"Price List for Basic Airport Services\" issued on 1 January 2002.\n",
      "\n",
      "Details recorded on the \"Load Sheets\" confirmed the handling charge of 1074 Euros was also found to be correct. The landing charge of €676.44 was, however, reduced by 50% as this flight was identified as a \"humanitarian flight\" and as such qualified for the discount. The Official of the Passenger Handling Services, Pristina Airport told the ITF Investigators that she regarded the returning Kosovars as refugees and the discount as appropriate. The ITF Investigators checked this matter with the Official of the Airport General Services, who confirmed he/she was aware of this discount and did not dispute this interpretation of the flight.\"\n",
      "Categories: Investigative Details\n",
      "Similarity Score: 0.3744855523109436\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_article = \"The first suspect to plead guilty in Singapore's largest money laundering case was convicted and sentenced to 13 months' jail in a district court on Tuesday (Apr 2). Su Wenqiang, 32, admitted to 11 charges of money laundering, possessing proceeds from illegal remote gambling offences and lying to get work passes for himself and his wife. More than S$3 billion (US$2.2 billion) in assets have been seized or frozen in relation to the case. This likely makes it one of the largest money laundering operations in the world. Su was among 10 suspects arrested in simultaneous police raids last August. The Cambodian national, whose passport states that he is from Fujian, was nabbed in a Good Class Bungalow along Lewis Road in Bukit Timah.\"\n",
    "similar_citations = find_most_similar_citations(news_article)\n",
    "\n",
    "for citation in similar_citations:\n",
    "    print(f\"Most Similar Citation: {citation['Citation Text']}\")\n",
    "    print(f\"Categories: {citation['Categories']}\")\n",
    "    print(f\"Similarity Score: {citation['Similarity Score']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Category' column has been successfully appended to the processed file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both Excel files\n",
    "wikileaks_data = pd.read_excel('wikileaks_parsed_with_categories.xlsx')\n",
    "processed_data = pd.read_excel('processed_wikileaks_parsed.xlsx')\n",
    "\n",
    "# Ensure both DataFrames have the same case for matching columns\n",
    "wikileaks_data['PDF Path'] = wikileaks_data['PDF Path'].str.strip()\n",
    "processed_data['PDF Path'] = processed_data['PDF Path'].str.strip()\n",
    "wikileaks_data['Text'] = wikileaks_data['Text'].str.strip()\n",
    "processed_data['Text'] = processed_data['Text'].str.strip()\n",
    "\n",
    "# Merge the dataframes on 'PDF Path' and 'Text'\n",
    "merged_data = pd.merge(processed_data, wikileaks_data[['PDF Path', 'Text', 'Category']],\n",
    "                       on=['PDF Path', 'Text'], how='left')\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "merged_data.to_excel('processed_wikileaks_parsed_with_category.xlsx', index=False)\n",
    "\n",
    "print(\"The 'Category' column has been successfully appended to the processed file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Category' column has been successfully appended to the processed file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both Excel files\n",
    "wikileaks_data = pd.read_excel('news_excerpts_parsed_with_categories.xlsx')\n",
    "processed_data = pd.read_excel('processed_news_excerpts_parsed.xlsx')\n",
    "\n",
    "# Ensure both DataFrames have the same case for matching columns\n",
    "wikileaks_data['Link'] = wikileaks_data['Link'].str.strip()\n",
    "processed_data['Link'] = processed_data['Link'].str.strip()\n",
    "wikileaks_data['Text'] = wikileaks_data['Text'].str.strip()\n",
    "processed_data['Text'] = processed_data['Text'].str.strip()\n",
    "\n",
    "# Merge the dataframes on 'PDF Path' and 'Text'\n",
    "merged_data = pd.merge(processed_data, wikileaks_data[['Link', 'Text', 'Category']],\n",
    "                       on=['Link', 'Text'], how='left')\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "merged_data.to_excel('processed_news_excerpts_parsed_with_category.xlsx', index=False)\n",
    "\n",
    "print(\"The 'Category' column has been successfully appended to the processed file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Wikileaks documents per group saved to sentencebert_top5_wikileaks_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "input_file = \"./data/sentencebert_results.xlsx\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Sort by 'Method', 'news_Link', and 'content_similarity' in descending order\n",
    "df_sorted = df.sort_values(by=['Method', 'news_Link', 'content_similarity'], ascending=[True, True, False])\n",
    "\n",
    "# Select the top 5 Wikileaks documents for each 'Method' and 'news_Link' group\n",
    "df_top5 = df_sorted.groupby(['Method', 'news_Link']).head(5).reset_index(drop=True)\n",
    "\n",
    "# Save the resulting DataFrame to a new Excel file\n",
    "output_file = \"sentencebert_top5_wikileaks_results.xlsx\"\n",
    "df_top5.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Top 5 Wikileaks documents per group saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Excel file with top 5 Wikileaks documents for each news excerpt has been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"./data/cited_judgments_with_news_articles.xlsx\")\n",
    "\n",
    "# Sort the dataframe by 'news_Link' and 'content_similarity' in descending order\n",
    "df_sorted = df.sort_values(by=['news_Link', 'content_similarity'], ascending=[True, False])\n",
    "\n",
    "# Group by 'news_Link' and select the top 5 rows for each group\n",
    "df_top5 = df_sorted.groupby('news_Link').head(5).reset_index(drop=True)\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "df_top5.to_excel(\"top5_cited_judgments_with_news_articles.xlsx\", index=False)\n",
    "\n",
    "print(\"Filtered Excel file with top 5 Wikileaks documents for each news excerpt has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file saved as combined_top5_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original Excel files\n",
    "cited_judgments_file = \"./data/top5_cited_judgments_with_news_articles.xlsx\"\n",
    "sentencebert_file = \"./data/sentencebert_top5_wikileaks_results.xlsx\"\n",
    "\n",
    "# Read the cited judgments data\n",
    "cited_df = pd.read_excel(cited_judgments_file)\n",
    "\n",
    "# Sort by content similarity and keep the top 5 rows per news_Link\n",
    "top5_cited_df = (\n",
    "    cited_df.sort_values(by=[\"news_Link\", \"content_similarity\"], ascending=[True, False])\n",
    "    .groupby(\"news_Link\")\n",
    "    .head(5)\n",
    ")\n",
    "\n",
    "# Read the SentenceBERT results\n",
    "top5_sentencebert_df = pd.read_excel(sentencebert_file)\n",
    "\n",
    "# Merge the top 5 cited judgments with SentenceBERT results\n",
    "# Assuming both datasets have the `news_Link` column for alignment\n",
    "merged_df = pd.merge(top5_sentencebert_df, top5_cited_df, on=\"news_Link\", how=\"outer\")\n",
    "\n",
    "# Save the merged results into a new Excel file\n",
    "output_file = \"combined_top5_results.xlsx\"\n",
    "merged_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Combined file saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
